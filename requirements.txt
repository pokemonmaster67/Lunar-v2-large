torch>=2.0.0
transformers>=4.30.0
accelerate>=0.20.0
bitsandbytes>=0.39.0
flash-attn>=2.0.0
datasets>=2.12.0
wandb>=0.15.0
numpy>=1.24.0
tqdm>=4.65.0
sentencepiece>=0.1.99
tokenizers>=0.13.3
huggingface_hub>=0.15.1
scipy>=1.10.0
einops>=0.6.1
